{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q -U tf-models-official\n",
        "!pip install -U tfds-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79yQzenragku",
        "outputId": "935e62f6-d1b0-46fa-9b7a-1f7e974cd573"
      },
      "id": "79yQzenragku",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.7/dist-packages (4.4.0.dev202201010107)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.23.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (5.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (4.62.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.3.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tfds-nightly) (3.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly) (1.53.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aphsv-q4dI5v",
        "outputId": "def7762b-abb3-47a6-997b-8387943f28b5"
      },
      "id": "aphsv-q4dI5v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f671240b-942c-47cb-82a7-1dca51b40601",
      "metadata": {
        "id": "f671240b-942c-47cb-82a7-1dca51b40601"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "!pip install tensorflow-addons\n",
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q -U tf-models-official\n",
        "!pip install -U tfds-nightly\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa # For metrics\n",
        "from official.nlp import optimization\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "\"\"\"\n",
        "Configure TFHub to read checkpoints directly from TFHub's Cloud Storage buckets. This is only recommended when running TFHub models on TPU.\n",
        "Without this setting TFHub would download the compressed file and extract the checkpoint locally. Attempting to load from these local files will fail with the following error:\n",
        "```\n",
        "InvalidArgumentError: Unimplemented: File system scheme '[local]' not implemented\n",
        "```\n",
        "This is because the [TPU can only read directly from Cloud Storage buckets](https://cloud.google.com/tpu/docs/troubleshooting#cannot_use_local_filesystem).\n",
        "Note: This setting is automatic in Colab.\n",
        "\"\"\"\n",
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "\n",
        "\n",
        "class BERT_FineTune:\n",
        "    def __init__(self, handle_encoder, handle_preprocess):\n",
        "      try:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        strategy = tf.distribute.TPUStrategy(resolver)\n",
        "        print('Using TPU')\n",
        "      except:\n",
        "        if tf.config.list_physical_devices('GPU'):\n",
        "            strategy = tf.distribute.MirroredStrategy()\n",
        "            print('Using GPU')\n",
        "        else:\n",
        "            strategy = None\n",
        "            print('Running on CPU is not recommended.')\n",
        "      self.strategy = strategy\n",
        "      self.handle_encoder = handle_encoder\n",
        "      self.handle_preprocess = handle_preprocess\n",
        "\n",
        "    @staticmethod\n",
        "    def make_bert_preprocess_model(handle_preprocess, sentence_features, seq_length=128):\n",
        "        \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "\n",
        "        Args:\n",
        "        sentence_features: a list with the names of string-valued features.\n",
        "        seq_length: an integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "        Returns:\n",
        "        A Keras Model that can be called on a list or dict of string Tensors\n",
        "        (with the order or names, resp., given by sentence_features) and\n",
        "        returns a dict of tensors for input to BERT.\n",
        "        \"\"\"\n",
        "\n",
        "        input_segments = [\n",
        "            tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "            for ft in sentence_features]\n",
        "\n",
        "        # Tokenize the text to word pieces.\n",
        "        bert_preprocess = hub.load(handle_preprocess)\n",
        "        tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "        segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "        # Optional: Trim segments in a smart way to fit seq_length.\n",
        "        # Simple cases (like this example) can skip this step and let\n",
        "        # the next step apply a default truncation to approximately equal lengths.\n",
        "        truncated_segments = segments\n",
        "\n",
        "        # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "        # are model-dependent, so this gets loaded from the SavedModel.\n",
        "        packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                                arguments=dict(seq_length=seq_length),\n",
        "                                name='packer')\n",
        "        model_inputs = packer(truncated_segments)\n",
        "        return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_dataset(df, batch_size, bert_preprocess_model, sentence_features, label='label', shuffle=False, repeat=False):\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "        in_memory_ds = dict()\n",
        "        for feature in sentence_features:\n",
        "            in_memory_ds[feature] = df[feature]\n",
        "        in_memory_ds['label'] = df[label]\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds)\n",
        "        num_examples = len(in_memory_ds['label'])\n",
        "\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(num_examples)\n",
        "        if repeat:\n",
        "            dataset = dataset.repeat()\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        dataset = dataset.map(lambda ex: (bert_preprocess_model(ex), ex['label']))\n",
        "        dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "        return dataset, num_examples\n",
        "\n",
        "    @staticmethod\n",
        "    def build_classifier_model(encoder, num_classes, seed=0):\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "        class Classifier(tf.keras.Model):\n",
        "            def __init__(self, encoder, num_classes):\n",
        "                super(Classifier, self).__init__(name=\"prediction\")\n",
        "                self.encoder = encoder\n",
        "                self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "                self.dense = tf.keras.layers.Dense(num_classes)\n",
        "\n",
        "            def call(self, preprocessed_text):\n",
        "                encoder_outputs = self.encoder(preprocessed_text)\n",
        "                pooled_output = encoder_outputs[\"pooled_output\"]\n",
        "                x = self.dropout(pooled_output)\n",
        "                x = self.dense(x)\n",
        "                return x\n",
        "\n",
        "        model = Classifier(encoder, num_classes)\n",
        "        return model\n",
        "\n",
        "\n",
        "    def tune(self, train_df, val_df=None, sentence_features=['sentence'], label='label', epochs=3, batch_size=32, optimizer='sgd', seq_length=128):\n",
        "        num_classes = len(train_df[label].unique())\n",
        "        bert_preprocess_model = BERT_FineTune.make_bert_preprocess_model(self.handle_preprocess, sentence_features, seq_length)\n",
        "\n",
        "        train_dataset, train_data_size = BERT_FineTune.convert_dataset(\n",
        "            train_df, batch_size, bert_preprocess_model, sentence_features, label, True, True)\n",
        "\n",
        "        steps_per_epoch = train_data_size // batch_size\n",
        "        num_train_steps = steps_per_epoch * epochs\n",
        "        num_warmup_steps = num_train_steps // 10\n",
        "        \n",
        "        if val_df is None:\n",
        "            validation_dataset = None\n",
        "            validation_steps = None\n",
        "        else:\n",
        "            validation_dataset, validation_data_size = BERT_FineTune.convert_dataset(\n",
        "                val_df, batch_size, bert_preprocess_model, sentence_features, label, False, False)\n",
        "            validation_steps = validation_data_size // batch_size\n",
        "\n",
        "        \n",
        "        if self.strategy is None:\n",
        "            encoder = hub.KerasLayer(self.handle_encoder, trainable=True)\n",
        "\n",
        "            # metric have to be created inside the strategy scope\n",
        "\n",
        "            loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "            #metrics = tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2)\n",
        "            classifier_model = BERT_FineTune.build_classifier_model(encoder, num_classes)\n",
        "\n",
        "            # optimizer = optimization.create_optimizer(\n",
        "            #     init_lr=init_lr,\n",
        "            #     num_train_steps=num_train_steps,\n",
        "            #     num_warmup_steps=num_warmup_steps,\n",
        "            #     optimizer_type='adamw')\n",
        "\n",
        "            classifier_model.compile(optimizer=optimizer, loss=loss, metrics='accuracy') # metrics=[metrics]\n",
        "\n",
        "            classifier_model.fit(\n",
        "                x=train_dataset,\n",
        "                validation_data=validation_dataset,\n",
        "                steps_per_epoch=steps_per_epoch,\n",
        "                epochs=epochs,\n",
        "                validation_steps=validation_steps)\n",
        "        else:\n",
        "            with self.strategy.scope():\n",
        "                encoder = hub.KerasLayer(self.handle_encoder, trainable=True)\n",
        "\n",
        "                # metric have to be created inside the strategy scope\n",
        "\n",
        "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "                #metrics = tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2)\n",
        "\n",
        "                classifier_model = BERT_FineTune.build_classifier_model(encoder, num_classes)\n",
        "\n",
        "                # optimizer = optimization.create_optimizer(\n",
        "                #     init_lr=init_lr,\n",
        "                #     num_train_steps=num_train_steps,\n",
        "                #     num_warmup_steps=num_warmup_steps,\n",
        "                #     optimizer_type='adamw')\n",
        "\n",
        "                classifier_model.compile(optimizer=optimizer, loss=loss, metrics='accuracy') # metrics=[metrics]\n",
        "\n",
        "                classifier_model.fit(\n",
        "                    x=train_dataset,\n",
        "                    validation_data=validation_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=epochs,\n",
        "                    validation_steps=validation_steps)\n",
        "        return classifier_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Data/positive_data.csv')"
      ],
      "metadata": {
        "id": "PmuN7IwDb3wL"
      },
      "id": "PmuN7IwDb3wL",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msk = np.random.rand(len(data)) < 0.8\n",
        "\n",
        "train_df = data[msk]\n",
        "\n",
        "val_df = data[~msk]"
      ],
      "metadata": {
        "id": "nRYsyMt0cOUx"
      },
      "id": "nRYsyMt0cOUx",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4b2d4f0e-7f5a-4d6c-9a77-c21e7dde52d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "4b2d4f0e-7f5a-4d6c-9a77-c21e7dde52d3",
        "outputId": "a718f2fe-8abd-4ef5-997f-2c07927b1265"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a83ee67-5b06-4d82-aaf5-7538cf237db8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im sooo im gunna cry i ve been at this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me t_t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578622</th>\n",
              "      <td>1</td>\n",
              "      <td>zzzzzz finally night tweeters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578623</th>\n",
              "      <td>1</td>\n",
              "      <td>zzzzzzz sleep well people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578624</th>\n",
              "      <td>0</td>\n",
              "      <td>zzzzzzzzzz wait no i have homework</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578625</th>\n",
              "      <td>0</td>\n",
              "      <td>zzzzzzzzzzzzz meh what am i doing up again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578626</th>\n",
              "      <td>0</td>\n",
              "      <td>zzzzzzzzzzzzzzzzzzz i wish</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1263190 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a83ee67-5b06-4d82-aaf5-7538cf237db8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a83ee67-5b06-4d82-aaf5-7538cf237db8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a83ee67-5b06-4d82-aaf5-7538cf237db8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         label                                           sentence\n",
              "0            0                        is so sad for my apl friend\n",
              "1            0                      i missed the new moon trailer\n",
              "2            1                                  omg its already o\n",
              "3            0  omgaga im sooo im gunna cry i ve been at this ...\n",
              "4            0                i think mi bf is cheating on me t_t\n",
              "...        ...                                                ...\n",
              "1578622      1                      zzzzzz finally night tweeters\n",
              "1578623      1                          zzzzzzz sleep well people\n",
              "1578624      0                 zzzzzzzzzz wait no i have homework\n",
              "1578625      0         zzzzzzzzzzzzz meh what am i doing up again\n",
              "1578626      0                         zzzzzzzzzzzzzzzzzzz i wish\n",
              "\n",
              "[1263190 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: total number of rows (1263190) exceeds max_rows (20000). Limiting to first (20000) rows.\n"
          ]
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['sentence']"
      ],
      "metadata": {
        "id": "aLdTAO32cwE9"
      },
      "id": "aLdTAO32cwE9",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "47ca33e2-750b-4548-acd5-f897315790dc",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ca33e2-750b-4548-acd5-f897315790dc",
        "outputId": "16fcb695-6cf1-4b5d-9f18-7fe5ec4166d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ],
      "source": [
        "# bert_finetune = BERT_FineTune(handle_encoder='/home/jupyter/BertPretained/bert_en_uncased_L-12_H-768_A-12', \n",
        "#                               handle_preprocess='/home/jupyter/BertPreprocess/bert_en_uncased_preprocess')\n",
        "\n",
        "bert_finetune = BERT_FineTune(handle_encoder='https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3', \n",
        "                              handle_preprocess='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "74709d3d-a5c0-4cc9-8c71-d9c7b0929dea",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74709d3d-a5c0-4cc9-8c71-d9c7b0929dea",
        "outputId": "78d6687b-7940-46b9-feae-becc8c2e09df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['label'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"SGD/gradients/StatefulPartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"SGD/gradients/StatefulPartitionedCall:0\", dtype=float32), dense_shape=Tensor(\"SGD/gradients/StatefulPartitionedCall:2\", shape=(None,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39474/39474 [==============================] - 2188s 55ms/step - loss: 0.3644 - accuracy: 0.8379\n",
            "Epoch 2/3\n",
            "39474/39474 [==============================] - 2146s 54ms/step - loss: 0.3263 - accuracy: 0.8576\n",
            "Epoch 3/3\n",
            "39474/39474 [==============================] - 2173s 55ms/step - loss: 0.3066 - accuracy: 0.8673\n"
          ]
        }
      ],
      "source": [
        "bert_model = bert_finetune.tune(train_df, None, feature_cols,\n",
        "                   label='label', epochs=3,\n",
        "                   batch_size=32, optimizer='sgd', seq_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2e85b133-d7e0-4570-aa55-3e54827c33f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e85b133-d7e0-4570-aa55-3e54827c33f6",
        "outputId": "584d89c8-f017-4fa1-f276-6c61c17930a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['label'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        }
      ],
      "source": [
        "bert_preprocess_model = bert_finetune.make_bert_preprocess_model(bert_finetune.handle_preprocess,feature_cols, seq_length=128)\n",
        "test_ds, _=bert_finetune.convert_dataset(val_df, 32, \n",
        "                          bert_preprocess_model, \n",
        "                          feature_cols, \n",
        "                          label='label', shuffle=False, repeat=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4f60ceaf-57de-4754-a91f-6b740ee079a3",
      "metadata": {
        "id": "4f60ceaf-57de-4754-a91f-6b740ee079a3"
      },
      "outputs": [],
      "source": [
        "with bert_finetune.strategy.scope():\n",
        "  predictions = bert_model.predict(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Y56N8vmMEWkw",
        "outputId": "b8baeb03-9b4f-488d-95eb-e31f165052f8"
      },
      "id": "Y56N8vmMEWkw",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-27dfd7c8-3c87-4504-a340-4670e9ca22fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>juuuuuuuuuuuuuuuuussssst chillin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>sunny again work tomorrow tv tonight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>hmmmm i wonder how she my number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>lt this is the way i feel right now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>awhhe man i m completely useless rt now funny ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578601</th>\n",
              "      <td>0</td>\n",
              "      <td>zootm cannot survive without crlf support wait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578604</th>\n",
              "      <td>1</td>\n",
              "      <td>zow finished uploading pictures on flickr and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578614</th>\n",
              "      <td>0</td>\n",
              "      <td>zzz time just wish my love could b nxt me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578617</th>\n",
              "      <td>0</td>\n",
              "      <td>zzzz lying in bed watching the countryside thr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578618</th>\n",
              "      <td>1</td>\n",
              "      <td>zzzz fuck zzzz fuck</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>315437 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27dfd7c8-3c87-4504-a340-4670e9ca22fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27dfd7c8-3c87-4504-a340-4670e9ca22fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27dfd7c8-3c87-4504-a340-4670e9ca22fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         label                                           sentence\n",
              "6            1                   juuuuuuuuuuuuuuuuussssst chillin\n",
              "7            0               sunny again work tomorrow tv tonight\n",
              "9            1                   hmmmm i wonder how she my number\n",
              "15           0                lt this is the way i feel right now\n",
              "16           0  awhhe man i m completely useless rt now funny ...\n",
              "...        ...                                                ...\n",
              "1578601      0     zootm cannot survive without crlf support wait\n",
              "1578604      1  zow finished uploading pictures on flickr and ...\n",
              "1578614      0          zzz time just wish my love could b nxt me\n",
              "1578617      0  zzzz lying in bed watching the countryside thr...\n",
              "1578618      1                                zzzz fuck zzzz fuck\n",
              "\n",
              "[315437 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "102e6fc1-e2ce-4399-a09e-00d0ed2a4901",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "102e6fc1-e2ce-4399-a09e-00d0ed2a4901",
        "outputId": "9920b6a2-5277-4a29-e920-c2240a6418d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8603542857229131"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "pred = np.argmax(predictions, axis=1)\n",
        "real = val_df['label']\n",
        "f1_score(real, pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3a840a-3978-4f6a-815c-43b1bcf1398e",
      "metadata": {
        "id": "ed3a840a-3978-4f6a-815c-43b1bcf1398e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(\n",
        "    bert_model, '/content/drive/MyDrive/Data/bert', overwrite=True, include_optimizer=True, save_format=None,\n",
        "    signatures=None, options=None, save_traces=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "CH5W9ZcGFMUZ",
        "outputId": "1aa84c69-0bef-41d0-f77d-7bf8d8f48c41"
      },
      "id": "CH5W9ZcGFMUZ",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e0a34b86160b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.keras.models.save_model(\n\u001b[1;32m      2\u001b[0m     \u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Data/bert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msignatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/content/drive/MyDrive/Data/bert/variables/variables_temp/part-00000-of-00001')\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:MergeV2Checkpoints]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = tf.saved_model.load(\n",
        "    '/content/drive/MyDrive/Data/bert', tags=None, options=None\n",
        ")"
      ],
      "metadata": {
        "id": "JmRFmI0fGKqd"
      },
      "id": "JmRFmI0fGKqd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-7.m86",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m86"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "BERTClass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}